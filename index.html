<!DOCTYPE html>
<html lang="ru">
  <head>
    <title>Определение привлекательности человека по фото</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- prettier-ignore -->
    <link rel="stylesheet" href="node_modules/@shower/ribbon/styles/styles.css">
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body class="shower list">
    <header class="caption">
      <h1>Определение привлекательности человека по фото</h1>
      <p>Facial Beauty Prediction</p>
    </header>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://www.mdpi.com/2078-2489/11/8/391/htm"
          target="_blank"
          rel="noopener noreferrer"
          >Deep learning for facial beauty prediction</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>Kerang Cao, Kwang-nam Choi, Hoekyung Jung, Lini Duan</dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>Information (Switzerland)</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2020</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>13 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://www.mdpi.com/2078-2489/11/8/391/htm"
          target="_blank"
          rel="noopener noreferrer"
          >Deep learning for facial beauty prediction</a
        >
      </p>
      <p>
        Facial beauty prediction (FBP) is a burgeoning issue for attractiveness
        evaluation, which aims to make assessment consistent with human opinion.
        Since FBP is a regression problem, to handle this issue, there are
        data-driven methods for finding the relations between facial features
        and beauty assessment. Recently, deep learning methods have shown its
        amazing capacity for feature representation and analysis. Convolutional
        neural networks (CNNs) have shown tremendous performance on facial
        recognition and comprehension, which are proved as an effective method
        for facial feature exploration. Lately, there are well-designed networks
        with efficient structures investigated for better representation
        performance. However, these designs concentrate on the effective block
        but do not build an efficient information transmission pathway, which
        led to a sub-optimal capacity for feature representation. Furthermore,
        these works cannot find the inherent correlations of feature maps, which
        also limits the performance. In this paper, an elaborate network design
        for FBP issue is proposed for better performance. A residual-in-residual
        (RIR) structure is introduced to the network for passing the gradient
        flow deeper, and building a better pathway for information transmission.
        By applying the RIR structure, a deeper network can be established for
        better feature representation. Besides the RIR network design, an
        attention mechanism is introduced to exploit the inner correlations
        among features. We investigate a joint spatial-wise and channel-wise
        attention (SCA) block to distribute the importance among features, which
        finds a better representation for facial information. Experimental
        results show our proposed network can predict facial beauty closer to a
        human's assessment than state-of-the-arts.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/2599699/Deep-facial-features-for-personalized-attractiveness-prediction/10.1117/12.2599699.short"
          target="_blank"
          rel="noopener noreferrer"
          >Deep facial features for personalized attractiveness prediction</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>Irina Lebedeva, Yi Guo, Fangli Ying</dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>
          Proceedings of SPIE - The International Society for Optical
          Engineering
        </dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2021</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>2 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11878/2599699/Deep-facial-features-for-personalized-attractiveness-prediction/10.1117/12.2599699.short"
          target="_blank"
          rel="noopener noreferrer"
          >Deep facial features for personalized attractiveness prediction</a
        >
      </p>
      <p>
        In this work, we propose a novel personalized facial attractiveness
        prediction method that is able to effectively learn an individual's
        preferences on few training images. A deep convolutional neural network
        (CNN) was first employed to estimate facial attributes. Then the
        attributes that play the most significant role for the individual were
        selected to train Random Forest. A new dataset specially created for
        personalized beauty evaluation was also proposed. Our method has
        achieved promising results of 54% Pearson's Correlation on 15 training
        images, 61% on 35 images.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://link.springer.com/chapter/10.1007/978-3-030-30604-5_22"
          target="_blank"
          rel="noopener noreferrer"
          >Machine-Learning and R in Plastic Surgery – Evaluation of Facial
          Attractiveness and Classification of Facial Emotions</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>Lubomír Štěpánek, Pavel Kasal, Jan Měšťák</dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>Advances in Intelligent Systems and Computing</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2019</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>10 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://link.springer.com/chapter/10.1007/978-3-030-30604-5_22"
          target="_blank"
          rel="noopener noreferrer"
          >Machine-Learning and R in Plastic Surgery – Evaluation of Facial
          Attractiveness and Classification of Facial Emotions</a
        >
      </p>
      <p>
        Although facial attractiveness is data-driven and nondependent on a
        perceiver, traditional statistical methods cannot properly identify
        relationships between facial geometry and its visual impression.
        Similarly, classification of facial images into facial emotions is also
        challenging, since the classification should consider the fact that
        overall facial impression is always dependent on currently present
        facial emotion.
      </p>
      <p>
        To address the problems, both profile and portrait facial images of the
        patients (n=42) were preprocessed, landmarked, and analyzed via R
        language. Multivariate regression was carried out to detect indicators
        increasing facial attractiveness after going through rhinoplasty.
      </p>
      <p>
        Bayesian naive classifiers, decision trees (CART) and neural networks,
        respectively, were built to classify a new facial image into one of the
        facial emotions, defined using Ekman-Friesen FACS scale.
      </p>
      <p>
        Nasolabial and nasofrontal angles' enlargement within rhinoplasty
        increases facial attractiveness (p&lt;0.05). Decision trees proved the
        geometry of a mouth, then eyebrows and finally eyes affect in this
        descending order an impact on classified emotion. Neural networks
        returned the highest accuracy of the classification.
      </p>
      <p>
        Performed machine-learning analyses pointed out which facial features
        affect facial attractiveness the most and should be therefore treated by
        plastics surgery procedures. The classification of facial images into
        emotions show possible associations between facial geometry and facial
        emotions.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://journals.sagepub.com/doi/10.1177/2041669520961123"
          target="_blank"
          rel="noopener noreferrer"
          >The Influence of Each Facial Feature on How We Perceive and Interpret
          Human Faces</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>
          Jose A. Diego-Mas, Felix Fuentes-Hurtado, Valery Naranjo, Mariano
          Alcañiz
        </dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>i-Perception</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2020</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>10 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://journals.sagepub.com/doi/10.1177/2041669520961123"
          target="_blank"
          rel="noopener noreferrer"
          >The Influence of Each Facial Feature on How We Perceive and Interpret
          Human Faces</a
        >
      </p>
      <p>
        Facial information is processed by our brain in such a way that we
        immediately make judgments about, for example, attractiveness or
        masculinity or interpret personality traits or moods of other people.
        The appearance of each facial feature has an effect on our perception of
        facial traits. This research addresses the problem of measuring the size
        of these effects for five facial features (eyes, eyebrows, nose, mouth,
        and jaw). Our proposal is a mixed feature-based and image-based approach
        that allows judgments to be made on complete real faces in the
        categorization tasks, more than on synthetic, noisy, or partial faces
        that can influence the assessment. Each facial feature of the faces is
        automatically classified considering their global appearance using
        principal component analysis. Using this procedure, we establish a
        reduced set of relevant specific attributes (each one describing a
        complete facial feature) to characterize faces. In this way, a more
        direct link can be established between perceived facial traits and what
        people intuitively consider an eye, an eyebrow, a nose, a mouth, or a
        jaw. A set of 92 male faces were classified using this procedure, and
        the results were related to their scores in 15 perceived facial traits.
        We show that the relevant features greatly depend on what we are trying
        to judge. Globally, the eyes have the greatest effect. However, other
        facial features are more relevant for some judgments like the mouth for
        happiness and femininity or the nose for dominance.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://www.sciencedirect.com/science/article/pii/S0950705122000740?via%3Dihub"
          target="_blank"
          rel="noopener noreferrer"
          >Deep learning based face beauty prediction via dynamic robust losses
          and ensemble regression</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>F.Bougourzi, F.Dornaika, A.Taleb-Ahmed</dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>Knowledge-Based Systems</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2022</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>1 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://www.sciencedirect.com/science/article/pii/S0950705122000740?via%3Dihub"
          target="_blank"
          rel="noopener noreferrer"
          >Deep learning based face beauty prediction via dynamic robust losses
          and ensemble regression</a
        >
      </p>
      <p>
        In the last decade, several studies have shown that facial
        attractiveness can be learned by machines. In this paper, we address
        Facial Beauty Prediction from static images. The paper contains three
        main contributions. First, we propose a two-branch architecture
        (REX-INCEP) based on merging the architecture of two already trained
        networks to deal with the complicated high-level features associated
        with the FBP problem. Second, we introduce the use of a dynamic law to
        control the behaviour of the following robust loss functions during
        training: ParamSmoothL1, Huber and Tukey. Third, we propose an ensemble
        regression based on Convolutional Neural Networks (CNNs). In this
        ensemble, we use both the basic networks and our proposed network
        (REX-INCEP). The proposed individual CNN regressors are trained with
        different loss functions, namely MSE, dynamic ParamSmoothL1, dynamic
        Huber and dynamic Tukey. Our approach is evaluated on the SCUT-FBP5500
        database using the two evaluation scenarios provided by the database
        creators: 60%–40% split and five-fold cross-validation. In both
        evaluation scenarios, our approach outperforms the state of the art on
        several metrics. These comparisons highlight the effectiveness of the
        proposed solutions for FBP. They also show that the proposed dynamic
        robust losses lead to more flexible and accurate estimators.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://ieeexplore.ieee.org/document/8789541"
          target="_blank"
          rel="noopener noreferrer"
          >Regression Guided by Relative Ranking Using Convolutional Neural
          Network (R<sup>3</sup>CNN) for Facial Beauty Prediction</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>Luojun Lin, Lingyu Liang, Lianwen Jin</dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>IEEE Transactions on Affective Computing</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2022</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>1 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://ieeexplore.ieee.org/document/8789541"
          target="_blank"
          rel="noopener noreferrer"
          >Regression Guided by Relative Ranking Using Convolutional Neural
          Network (R<sup>3</sup>CNN) for Facial Beauty Prediction</a
        >
      </p>
      <p>
        Facial beauty prediction (FBP) aims to automatically assess facial
        attractiveness consistently with judgements based on human perception.
        Most of previous methods formulate FBP as a classification, regression
        or ranking problem of machine learning. However, humans not only
        represent facial attractiveness as a score, but also perceive the
        relative aesthetics of faces. Inspired by this observation, we formulate
        FBP as a specific regression problem guided by ranking information.
        Specifically, we propose a general CNN architecture, called
        R<sup>3</sup>CNN, to integrate the relative ranking of faces in terms of
        aesthetics to improve performance of FBP. As R<sup>3</sup>CNN consists
        of both regression and ranking components, it is challenging to train
        and fine-tune it by existing techniques. To tackle this problem, we
        propose the following learning schemes for R<sup>3</sup>CNN: 1) a hard
        pair sampling strategy that generates challenging-to-predicted image
        pairs and pseudo ranking labels from true rating scores; 2) an assemble
        loss function that combines regression loss and pairwise ranking loss
        (PR-Loss), where PR-Loss can be a hinge-form loss or a log-sum-exp
        pairwise loss; 3) a cascaded fine-tuning method that further improves
        prediction. Moreover, we build a benchmark dataset, called SCUT-FBP5500,
        containing 5,500 facial images with diverse properties (male/female,
        Asian/Caucasian, ages) and labels (face landmarks, rating scores within
        [1, 5], rating score distribution). Experiments were performed on both
        the SCUT-FBP and the SCUT-FBP5500 benchmark datasets, where our method
        achieves state-of-the-art performance on different evaluation settings.
        Comparisons with related CNN models highlight the effectiveness of the
        R<sup>3</sup>CNN architecture for FBP.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://www.sciencedirect.com/science/article/abs/pii/S0957417419307079?via%3Dihub"
          target="_blank"
          rel="noopener noreferrer"
          >Toward graph-based semi-supervised face beauty prediction</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>
          Fadi Dornaika, Kunwei Wang, Ignacio Arganda-Carreras, Anne Elorza,
          Abdelmalik Moujahid
        </dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>Expert Systems with Applications</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2020</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>10 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://www.sciencedirect.com/science/article/abs/pii/S0957417419307079?via%3Dihub"
          target="_blank"
          rel="noopener noreferrer"
          >Toward graph-based semi-supervised face beauty prediction</a
        >
      </p>
      <p>
        Assessing beauty using facial images analysis is an emerging computer
        vision problem. To the best of our knowledge, all existing methods for
        automatic facial beauty scoring rely on fully supervised schemes. In
        this paper, we introduce the use of semi-supervised learning schemes for
        solving the problem of face beauty scoring when the image descriptor is
        holistic and the score is given by a real number. The paper has two main
        contributions. Firstly, we introduce the use of graph-based
        semi-supervised learning for face beauty scoring. The proposed method is
        based on texture and utilizes continuous scores in a full range.
        Secondly, we adapt and kernelize an existing linear Flexible Manifold
        Embedding scheme (that works with discrete classes) to the case of real
        scores propagation. The resulting model can be used for transductive and
        inductive settings. The proposed semi-supervised schemes were evaluated
        on three recent public datasets for face beauty analysis: SCUT-FBP,
        M<sup>2</sup>B, and SCUT-FBP5500. The obtained experimental results, as
        well as many comparisons with fully supervised methods, demonstrate that
        the nonlinear semi-supervised scheme compares favorably with many
        supervised schemes. The proposed semi-supervised scoring framework paves
        the way to virtually all applications to adopt continuous scores instead
        of the usual discrete labels.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://ieeexplore.ieee.org/document/8967050"
          target="_blank"
          rel="noopener noreferrer"
          >2M BeautyNet: Facial beauty prediction based on multi-task transfer
          learning</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>
          Junying Gan, Li Xiang, Yikui Zhai, Chaoyun Mai, Guohui He, Junying
          Zeng, Zhenfeng Bai, Ruggero Donida Labati, Vincenzo Piuri, Fabio
          Scotti
        </dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>IEEE Access</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2020</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>8 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://ieeexplore.ieee.org/document/8967050"
          target="_blank"
          rel="noopener noreferrer"
          >2M BeautyNet: Facial beauty prediction based on multi-task transfer
          learning</a
        >
      </p>
      <p>
        Facial beauty prediction (FBP) has become an emerging area in the field
        of artificial intelligence. However, the lacks of data and accurate face
        representation hinder the development of FBP. Multi-task transfer
        learning can effectively avoid over-fitting, and utilize auxiliary
        information of related tasks to optimize the main task. In this paper,
        we present a network named Multi-input Multi-task Beauty Network (2M
        BeautyNet) and use transfer learning to predict facial beauty. In the
        experiment, beauty prediction is the main task, and gender recognition
        is the auxiliary. For multi-task training, we employ multi-task loss
        weights automatic learning strategy to improve the performance of FBP.
        Finally, we replace the softmax classifier with a random forest. We
        conduct experiments on the Large Scale Facial Beauty Database (LSFBD)
        and SCUT-FBP5500 database. Results show that our method has achieved
        good results on LSFBD, the accuracy of FBP is up to 68.23%. Our 2M
        BeautyNet structure is suitable for multiple inputs of different
        databases.
      </p>
    </section>

    <section class="slide info">
      <h3 class="title">
        <a
          href="https://www.hindawi.com/journals/cin/2021/4423407/"
          target="_blank"
          rel="noopener noreferrer"
          >Machine Learning-Based Facial Beauty Prediction and Analysis of
          Frontal Facial Images Using Facial Landmarks and Traditional Image
          Descriptors</a
        >
      </h3>
      <dl>
        <dt>Авторы:</dt>
        <dd>
          Tharun J. Iyer, Rahul K., Ruban Nersisson, Zhemin Zhuang, Alex Noel
          Joseph Raj, Imthiaz Refayee
        </dd>
      </dl>
      <dl>
        <dt>Издатель:</dt>
        <dd>Computational Intelligence and Neuroscience</dd>
      </dl>
      <dl>
        <dt>Год:</dt>
        <dd>2021</dd>
      </dl>
      <dl>
        <dt>Цитирований:</dt>
        <dd>4 (Scopus)</dd>
      </dl>
      <canvas class="code"></canvas>
    </section>

    <section class="slide anatation">
      <p class="title">
        <a
          href="https://www.hindawi.com/journals/cin/2021/4423407/"
          target="_blank"
          rel="noopener noreferrer"
          >Machine Learning-Based Facial Beauty Prediction and Analysis of
          Frontal Facial Images Using Facial Landmarks and Traditional Image
          Descriptors</a
        >
      </p>
      <p>
        The beauty industry has seen rapid growth in multiple countries and due
        to its applications in entertainment, the analysis and assessment of
        facial attractiveness have received attention from scientists,
        physicians, and artists because of digital media, plastic surgery, and
        cosmetics. An analysis of techniques is used in the assessment of facial
        beauty that considers facial ratios and facial qualities as elements to
        predict facial beauty. Here, the facial landmarks are extracted to
        calculate facial ratios according to Golden Ratios and Symmetry Ratios,
        and an ablation study is performed to find the best performing feature
        set from extracted ratios. Subsequently, Gray Level Covariance Matrix
        (GLCM), Hu's Moments, and Color Histograms in the HSV space are
        extracted as texture, shape, and color features, respectively. Another
        ablation study is performed to find out which feature performs the best
        when concatenated with the facial landmarks. Experimental results show
        that the concatenation of primary facial characteristics with facial
        landmarks improved the prediction score of facial beauty. Four models
        are trained, K-Nearest Neighbors (KNN), Linear Regression (LR), Random
        Forest (RF), and Artificial Neural Network (ANN) on a dataset of 5500
        frontal facial images, and amongst them, KNN performs the best for the
        concatenated features achieving a Pearson's Correlation Coefficient of
        0.7836 and a Mean Squared Error of 0.0963. Our analysis also provides us
        with insights into how different machine learning models can understand
        the concept of facial beauty.
      </p>
    </section>

    <!-- <footer class="badge">
      <a href="https://github.com/MarkOnegov/facial-beauty-prediction">
        Fork me on GitHub
      </a>
    </footer> -->

    <div class="progress"></div>

    <script src="node_modules/@shower/core/dist/shower.js"></script>
    <script src="node_modules/qrcode/build/qrcode.js"></script>
    <script src="./index.js"></script>
  </body>
</html>
